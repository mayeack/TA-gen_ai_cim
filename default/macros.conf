#
# macros.conf - Search Macros for GenAI CIM
# TA-gen_ai_cim
#
# Provides reusable macros for token cost calculations and governance analytics
#

###############################################################################
# TOKEN COST CALCULATION MACROS
###############################################################################

# ============================================================================
# genai_token_cost_join
# ============================================================================
# Primary macro for joining token costs to GenAI events based on:
# - provider (gen_ai.provider.name)
# - model (gen_ai.request.model)
# - _time (matched against effective_start/effective_end range)
#
# Adds fields:
# - gen_ai.cost.input_per_million, gen_ai.cost.output_per_million
# - gen_ai.cost.input, gen_ai.cost.output, gen_ai.cost.calculated_total
# - gen_ai.cost.currency
#
# Usage:
#   index=gen_ai_cim | `genai_token_cost_join`
# ============================================================================
[genai_token_cost_join]
definition = \
    eval _event_time = _time \
    | join type=left gen_ai.provider.name, gen_ai.request.model \
        [ | inputlookup genai_token_cost_lookup \
        | where direction="input" \
        | rename provider AS gen_ai.provider.name, model AS gen_ai.request.model, \
                 cost_per_million AS _input_cpm, effective_start AS _input_eff_start, \
                 effective_end AS _input_eff_end, currency AS _input_currency ] \
    | join type=left gen_ai.provider.name, gen_ai.request.model \
        [ | inputlookup genai_token_cost_lookup \
        | where direction="output" \
        | rename provider AS gen_ai.provider.name, model AS gen_ai.request.model, \
                 cost_per_million AS _output_cpm, effective_start AS _output_eff_start, \
                 effective_end AS _output_eff_end ] \
    | where (isnull(_input_eff_start) OR _event_time >= _input_eff_start) \
            AND (isnull(_input_eff_end) OR _event_time < _input_eff_end) \
    | where (isnull(_output_eff_start) OR _event_time >= _output_eff_start) \
            AND (isnull(_output_eff_end) OR _event_time < _output_eff_end) \
    | eval "gen_ai.cost.input_per_million" = _input_cpm, \
           "gen_ai.cost.output_per_million" = _output_cpm, \
           "gen_ai.cost.input" = round(coalesce('gen_ai.usage.input_tokens', 0) * coalesce(_input_cpm, 0) / 1000000, 8), \
           "gen_ai.cost.output" = round(coalesce('gen_ai.usage.output_tokens', 0) * coalesce(_output_cpm, 0) / 1000000, 8), \
           "gen_ai.cost.calculated_total" = round((coalesce('gen_ai.usage.input_tokens', 0) * coalesce(_input_cpm, 0) / 1000000) + (coalesce('gen_ai.usage.output_tokens', 0) * coalesce(_output_cpm, 0) / 1000000), 8), \
           "gen_ai.cost.currency" = coalesce(_input_currency, "USD") \
    | fields - _event_time, _input_cpm, _output_cpm, _input_eff_start, _input_eff_end, \
               _output_eff_start, _output_eff_end, _input_currency
iseval = 0

# ============================================================================
# genai_token_cost_join_subsearch
# ============================================================================
# Alternative implementation using subsearch for environments where
# join performance may be a concern. Uses map for row-by-row lookup.
#
# Usage:
#   index=gen_ai_cim | `genai_token_cost_join_subsearch`
# ============================================================================
[genai_token_cost_join_subsearch]
definition = \
    eval _event_time = _time \
    | lookup genai_token_cost_lookup provider AS gen_ai.provider.name, model AS gen_ai.request.model, direction AS _input_dir OUTPUT cost_per_million AS _input_cpm, effective_start AS _input_eff_start, effective_end AS _input_eff_end, currency AS _cost_currency \
    | eval _input_dir = "input" \
    | lookup genai_token_cost_lookup provider AS gen_ai.provider.name, model AS gen_ai.request.model, direction AS _output_dir OUTPUT cost_per_million AS _output_cpm, effective_start AS _output_eff_start, effective_end AS _output_eff_end \
    | eval _output_dir = "output" \
    | where (isnull(_input_eff_start) OR _event_time >= _input_eff_start) \
            AND (isnull(_input_eff_end) OR _event_time < _input_eff_end) \
    | where (isnull(_output_eff_start) OR _event_time >= _output_eff_start) \
            AND (isnull(_output_eff_end) OR _event_time < _output_eff_end) \
    | eval "gen_ai.cost.input_per_million" = _input_cpm, \
           "gen_ai.cost.output_per_million" = _output_cpm, \
           "gen_ai.cost.input" = round(coalesce('gen_ai.usage.input_tokens', 0) * coalesce(_input_cpm, 0) / 1000000, 8), \
           "gen_ai.cost.output" = round(coalesce('gen_ai.usage.output_tokens', 0) * coalesce(_output_cpm, 0) / 1000000, 8), \
           "gen_ai.cost.calculated_total" = round((coalesce('gen_ai.usage.input_tokens', 0) * coalesce(_input_cpm, 0) / 1000000) + (coalesce('gen_ai.usage.output_tokens', 0) * coalesce(_output_cpm, 0) / 1000000), 8), \
           "gen_ai.cost.currency" = coalesce(_cost_currency, "USD") \
    | fields - _event_time, _input_cpm, _output_cpm, _input_eff_start, _input_eff_end, \
               _output_eff_start, _output_eff_end, _input_dir, _output_dir, _cost_currency
iseval = 0

# ============================================================================
# genai_token_cost_summary(1)
# ============================================================================
# Calculates cost summary statistics with time-based grouping.
# Argument: time span (e.g., 1h, 1d, 1w)
#
# Usage:
#   index=gen_ai_cim | `genai_token_cost_join` | `genai_token_cost_summary(1d)`
# ============================================================================
[genai_token_cost_summary(1)]
args = span
definition = \
    bucket _time span=$span$ \
    | stats sum(gen_ai.cost.input) AS total_input_cost, \
            sum(gen_ai.cost.output) AS total_output_cost, \
            sum(gen_ai.cost.calculated_total) AS total_cost, \
            sum(gen_ai.usage.input_tokens) AS total_input_tokens, \
            sum(gen_ai.usage.output_tokens) AS total_output_tokens, \
            count AS request_count, \
            dc(gen_ai.request.model) AS unique_models, \
            dc(gen_ai.provider.name) AS unique_providers, \
            values(gen_ai.cost.currency) AS currency \
        by _time, gen_ai.provider.name, gen_ai.request.model \
    | eval avg_cost_per_request = round(total_cost / request_count, 6)
iseval = 0

# ============================================================================
# genai_cost_by_provider
# ============================================================================
# Aggregates total costs by provider
#
# Usage:
#   index=gen_ai_cim | `genai_token_cost_join` | `genai_cost_by_provider`
# ============================================================================
[genai_cost_by_provider]
definition = \
    stats sum(gen_ai.cost.input) AS total_input_cost, \
          sum(gen_ai.cost.output) AS total_output_cost, \
          sum(gen_ai.cost.calculated_total) AS total_cost, \
          sum(gen_ai.usage.input_tokens) AS total_input_tokens, \
          sum(gen_ai.usage.output_tokens) AS total_output_tokens, \
          count AS request_count, \
          dc(gen_ai.request.model) AS unique_models \
      by gen_ai.provider.name \
    | eval avg_cost_per_request = round(total_cost / request_count, 6), \
           input_cost_pct = round(total_input_cost / total_cost * 100, 2), \
           output_cost_pct = round(total_output_cost / total_cost * 100, 2) \
    | sort - total_cost
iseval = 0

# ============================================================================
# genai_cost_by_model
# ============================================================================
# Aggregates total costs by model
#
# Usage:
#   index=gen_ai_cim | `genai_token_cost_join` | `genai_cost_by_model`
# ============================================================================
[genai_cost_by_model]
definition = \
    stats sum(gen_ai.cost.input) AS total_input_cost, \
          sum(gen_ai.cost.output) AS total_output_cost, \
          sum(gen_ai.cost.calculated_total) AS total_cost, \
          sum(gen_ai.usage.input_tokens) AS total_input_tokens, \
          sum(gen_ai.usage.output_tokens) AS total_output_tokens, \
          count AS request_count \
      by gen_ai.provider.name, gen_ai.request.model \
    | eval avg_cost_per_request = round(total_cost / request_count, 6), \
           avg_tokens_per_request = round((total_input_tokens + total_output_tokens) / request_count, 0) \
    | sort - total_cost
iseval = 0

# ============================================================================
# genai_cost_by_app
# ============================================================================
# Aggregates total costs by application/service
#
# Usage:
#   index=gen_ai_cim | `genai_token_cost_join` | `genai_cost_by_app`
# ============================================================================
[genai_cost_by_app]
definition = \
    stats sum(gen_ai.cost.input) AS total_input_cost, \
          sum(gen_ai.cost.output) AS total_output_cost, \
          sum(gen_ai.cost.calculated_total) AS total_cost, \
          sum(gen_ai.usage.input_tokens) AS total_input_tokens, \
          sum(gen_ai.usage.output_tokens) AS total_output_tokens, \
          count AS request_count, \
          dc(gen_ai.request.model) AS unique_models \
      by gen_ai.app.name \
    | eval avg_cost_per_request = round(total_cost / request_count, 6) \
    | sort - total_cost
iseval = 0

# ============================================================================
# genai_cost_timechart(1)
# ============================================================================
# Creates a timechart of costs with specified span
# Argument: time span (e.g., 1h, 1d)
#
# Usage:
#   index=gen_ai_cim | `genai_token_cost_join` | `genai_cost_timechart(1h)`
# ============================================================================
[genai_cost_timechart(1)]
args = span
definition = \
    timechart span=$span$ \
        sum(gen_ai.cost.calculated_total) AS total_cost, \
        sum(gen_ai.cost.input) AS input_cost, \
        sum(gen_ai.cost.output) AS output_cost, \
        sum(gen_ai.usage.input_tokens) AS input_tokens, \
        sum(gen_ai.usage.output_tokens) AS output_tokens, \
        count AS requests
iseval = 0

# ============================================================================
# genai_get_current_pricing
# ============================================================================
# Retrieves current (active) pricing for all provider/model combinations
#
# Usage:
#   | `genai_get_current_pricing`
# ============================================================================
[genai_get_current_pricing]
definition = \
    inputlookup genai_token_cost_lookup \
    | eval _now = now() \
    | where (isnull(effective_end) OR effective_end > _now) \
            AND (isnull(effective_start) OR effective_start <= _now) \
    | fields - _now \
    | stats values(cost_per_million) AS cost_per_million, \
            values(effective_start) AS effective_start, \
            values(effective_end) AS effective_end, \
            values(currency) AS currency \
        by provider, model, direction \
    | sort provider, model, direction
iseval = 0

# ============================================================================
# genai_get_pricing_history(2)
# ============================================================================
# Retrieves pricing history for a specific provider and model
# Arguments: provider, model
#
# Usage:
#   | `genai_get_pricing_history("openai", "gpt-4")`
# ============================================================================
[genai_get_pricing_history(2)]
args = provider, model
definition = \
    inputlookup genai_token_cost_lookup \
    | where provider="$provider$" AND model="$model$" \
    | eval effective_start_human = strftime(effective_start, "%Y-%m-%d %H:%M:%S"), \
           effective_end_human = if(isnull(effective_end), "current", strftime(effective_end, "%Y-%m-%d %H:%M:%S")) \
    | sort direction, - effective_start \
    | table provider, model, direction, cost_per_million, currency, effective_start_human, effective_end_human, _key
iseval = 0

###############################################################################
# TF-IDF ANOMALY DETECTION MACROS
###############################################################################

# ============================================================================
# genai_tfidf_preprocess_prompt
# ============================================================================
# Preprocesses prompt text for TF-IDF vectorization
# Extracts and cleans gen_ai.input.messages for model input
# IMPORTANT: Captures anomaly-indicative signals BEFORE text normalization
#
# Usage:
#   index=gen_ai_cim | `genai_tfidf_preprocess_prompt`
# ============================================================================
[genai_tfidf_preprocess_prompt]
definition = \
    eval input_text=coalesce(mvjoin('input_messages{}.content', " "), 'gen_ai.input.messages', 'event.input', input_messages, input) \
    | where isnotnull(input_text) AND len(input_text) > 10 \
    | eval prompt_length_raw=len(input_text) \
    | eval prompt_special_char_count=len(replace(input_text, "[A-Za-z0-9\s]", "")) \
    | eval prompt_special_char_ratio=if(prompt_length_raw>0, round(prompt_special_char_count/prompt_length_raw, 4), 0) \
    | eval prompt_uppercase_count=len(replace(input_text, "[^A-Z]", "")) \
    | eval prompt_uppercase_ratio=if(prompt_length_raw>0, round(prompt_uppercase_count/prompt_length_raw, 4), 0) \
    | eval prompt_has_brackets=if(match(input_text, "[\[\]\{\}\<\>]"), 1, 0) \
    | eval prompt_has_delimiters=if(match(input_text, "(---|\*\*\*|###|```|\\[INST\\]|\\[/INST\\]|<<SYS>>|<</SYS>>|<\|im_start\|>|<\|im_end\|>)"), 1, 0) \
    | eval prompt_has_injection_markers=if(match(lower(input_text), "(ignore|disregard|forget|bypass|override).*(previous|prior|above|earlier|system|instruction|rule|prompt|safety|filter|guardrail)"), 1, 0) \
    | eval prompt_has_roleplay=if(match(lower(input_text), "(pretend|act as|imagine you are|you are now|from now on|new persona|new identity).*(no limits|unrestricted|unfiltered|without rules|anything)"), 1, 0) \
    | eval prompt_has_jailbreak_terms=if(match(lower(input_text), "(jailbreak|DAN|sudo mode|developer mode|god mode|admin mode|STAN|DUDE|AntiGPT|evil mode|uncensored|unaligned)"), 1, 0) \
    | eval prompt_has_encoding=if(match(input_text, "(\\\\x[0-9a-fA-F]{2}|%[0-9a-fA-F]{2}|&#\d+;|&#x[0-9a-fA-F]+;|base64|rot13|decode|encode|hex|ascii)"), 1, 0) \
    | eval prompt_has_repeated_chars=if(match(input_text, "(.)\\1{4,}"), 1, 0) \
    | eval prompt_pattern_score=(prompt_has_injection_markers*3 + prompt_has_jailbreak_terms*3 + prompt_has_roleplay*2 + prompt_has_encoding*2 + prompt_has_delimiters*1 + prompt_has_brackets*1 + prompt_has_repeated_chars*1) \
    | eval input_text_clean=lower(input_text) \
    | eval input_text_clean=replace(input_text_clean, "[^a-z0-9\s]", " ") \
    | eval input_text_clean=replace(input_text_clean, "\s+", " ") \
    | eval input_text_clean=trim(input_text_clean) \
    | where len(input_text_clean) > 20
iseval = 0

# ============================================================================
# genai_tfidf_preprocess_response
# ============================================================================
# Preprocesses response text for TF-IDF vectorization
# Extracts and cleans gen_ai.output.messages for model input
# IMPORTANT: Captures anomaly-indicative signals BEFORE text normalization
#
# Usage:
#   index=gen_ai_cim | `genai_tfidf_preprocess_response`
# ============================================================================
[genai_tfidf_preprocess_response]
definition = \
    eval output_text=coalesce(mvjoin('output_messages{}.content', " "), 'gen_ai.output.messages', 'event.output', output_messages, output) \
    | where isnotnull(output_text) AND len(output_text) > 20 \
    | eval response_length_raw=len(output_text) \
    | eval response_special_char_count=len(replace(output_text, "[A-Za-z0-9\s]", "")) \
    | eval response_special_char_ratio=if(response_length_raw>0, round(response_special_char_count/response_length_raw, 4), 0) \
    | eval response_has_harmful_content=if(match(lower(output_text), "(how to make|instructions for|step by step).*(bomb|weapon|hack|exploit|attack|malware|virus|illegal|harmful)"), 1, 0) \
    | eval response_has_jailbreak_confirm=if(match(lower(output_text), "(i am now|i will now|entering|activated|enabled).*(DAN|jailbreak|unrestricted|unfiltered|bypass|developer mode)"), 1, 0) \
    | eval response_has_system_leak=if(match(lower(output_text), "(system prompt|my instructions|i was told|i am programmed|my purpose is|my rules are)"), 1, 0) \
    | eval response_pattern_score=(response_has_harmful_content*3 + response_has_jailbreak_confirm*3 + response_has_system_leak*2) \
    | eval output_text_clean=lower(output_text) \
    | eval output_text_clean=replace(output_text_clean, "[^a-z0-9\s]", " ") \
    | eval output_text_clean=replace(output_text_clean, "\s+", " ") \
    | eval output_text_clean=trim(output_text_clean) \
    | where len(output_text_clean) > 50
iseval = 0

# ============================================================================
# genai_tfidf_anomaly_threshold
# ============================================================================
# Configurable threshold for OneClassSVM anomaly detection
# Default: 0.5 (more sensitive than original threshold of 0)
# Lower values = more sensitive (more anomalies detected)
# Higher values = less sensitive (fewer false positives)
# Range: -2.0 to 2.0 (typical OneClassSVM decision function range)
#
# Usage:
#   Modify this value to tune anomaly detection sensitivity
# ============================================================================
[genai_tfidf_anomaly_threshold]
definition = 0.5
iseval = 0

# ============================================================================
# genai_tfidf_pattern_threshold
# ============================================================================
# Pattern score threshold for rule-based anomaly detection
# Default: 2 (triggers on 2+ pattern matches)
# Pattern scores: jailbreak=3, injection_markers=3, roleplay=2, encoding=2, delimiters=1, brackets=1
#
# Usage:
#   Modify this value to tune pattern-based detection sensitivity
# ============================================================================
[genai_tfidf_pattern_threshold]
definition = 2
iseval = 0

# ============================================================================
# genai_tfidf_score_prompt
# ============================================================================
# Applies trained TF-IDF anomaly model to score prompts with HYBRID DETECTION
# Combines ML-based OneClassSVM detection with rule-based pattern detection
# Uses HashingVectorizer (stateless) inline, then applies PCA and OneClassSVM models
# Requires models: tfidf_prompt_pca, prompt_anomaly_model
#
# Hybrid Detection Logic:
#   1. ML Anomaly: isNormal < threshold (configurable via genai_tfidf_anomaly_threshold)
#   2. Pattern Match: prompt_pattern_score >= pattern_threshold (from preprocessing)
#   3. Final: is_anomaly = ML anomaly OR pattern match
#
# Usage:
#   index=gen_ai_cim | `genai_tfidf_preprocess_prompt` | `genai_tfidf_score_prompt`
# ============================================================================
[genai_tfidf_score_prompt]
definition = \
    fit HashingVectorizer input_text_clean max_features=1000 ngram_range=1-2 stop_words=english reduce=false \
    | apply app:tfidf_prompt_pca \
    | apply app:prompt_anomaly_model \
    | eval "gen_ai.prompt.anomaly_score" = 'isNormal' \
    | eval prompt_ml_anomaly = if('isNormal' < `genai_tfidf_anomaly_threshold`, 1, 0) \
    | eval prompt_pattern_anomaly = if(prompt_pattern_score >= `genai_tfidf_pattern_threshold`, 1, 0) \
    | eval "gen_ai.prompt.is_anomaly" = if(prompt_ml_anomaly=1 OR prompt_pattern_anomaly=1, "true", "false") \
    | eval "gen_ai.prompt.anomaly_source" = case( \
        prompt_ml_anomaly=1 AND prompt_pattern_anomaly=1, "ml_and_pattern", \
        prompt_ml_anomaly=1, "ml_only", \
        prompt_pattern_anomaly=1, "pattern_only", \
        1=1, "none" \
    ) \
    | eval prompt_word_count = mvcount(split(input_text_clean, " ")) \
    | eval prompt_char_count = len(input_text_clean)
iseval = 0

# ============================================================================
# genai_tfidf_score_response
# ============================================================================
# Applies trained TF-IDF anomaly model to score responses with HYBRID DETECTION
# Combines ML-based OneClassSVM detection with rule-based pattern detection
# Uses HashingVectorizer (stateless) inline, then applies PCA and OneClassSVM models
# Requires models: tfidf_response_pca, response_anomaly_model
#
# Hybrid Detection Logic:
#   1. ML Anomaly: isNormal < threshold (configurable via genai_tfidf_anomaly_threshold)
#   2. Pattern Match: response_pattern_score >= pattern_threshold (from preprocessing)
#   3. Final: is_anomaly = ML anomaly OR pattern match
#
# Usage:
#   index=gen_ai_cim | `genai_tfidf_preprocess_response` | `genai_tfidf_score_response`
# ============================================================================
[genai_tfidf_score_response]
definition = \
    fit HashingVectorizer output_text_clean max_features=1000 ngram_range=1-2 stop_words=english reduce=false \
    | apply app:tfidf_response_pca \
    | apply app:response_anomaly_model \
    | eval "gen_ai.response.anomaly_score" = 'isNormal' \
    | eval response_ml_anomaly = if('isNormal' < `genai_tfidf_anomaly_threshold`, 1, 0) \
    | eval response_pattern_anomaly = if(response_pattern_score >= `genai_tfidf_pattern_threshold`, 1, 0) \
    | eval "gen_ai.response.is_anomaly" = if(response_ml_anomaly=1 OR response_pattern_anomaly=1, "true", "false") \
    | eval "gen_ai.response.anomaly_source" = case( \
        response_ml_anomaly=1 AND response_pattern_anomaly=1, "ml_and_pattern", \
        response_ml_anomaly=1, "ml_only", \
        response_pattern_anomaly=1, "pattern_only", \
        1=1, "none" \
    ) \
    | eval response_word_count = mvcount(split(output_text_clean, " ")) \
    | eval response_char_count = len(output_text_clean)
iseval = 0

# ============================================================================
# genai_tfidf_preprocess_combined
# ============================================================================
# Preprocesses both prompt and response text for combined TF-IDF scoring
# Extracts and cleans both input and output messages for model input
# IMPORTANT: Captures anomaly-indicative signals BEFORE text normalization
#
# Usage:
#   index=gen_ai_cim | `genai_tfidf_preprocess_combined`
# ============================================================================
[genai_tfidf_preprocess_combined]
definition = \
    eval input_text=coalesce(mvjoin('input_messages{}.content', " "), 'gen_ai.input.messages', 'event.input', input_messages, input) \
    | eval output_text=coalesce(mvjoin('output_messages{}.content', " "), 'gen_ai.output.messages', 'event.output', output_messages, output) \
    | eval prompt_length_raw=len(coalesce(input_text, "")) \
    | eval prompt_special_char_count=len(replace(coalesce(input_text, ""), "[A-Za-z0-9\s]", "")) \
    | eval prompt_special_char_ratio=if(prompt_length_raw>0, round(prompt_special_char_count/prompt_length_raw, 4), 0) \
    | eval prompt_uppercase_count=len(replace(coalesce(input_text, ""), "[^A-Z]", "")) \
    | eval prompt_uppercase_ratio=if(prompt_length_raw>0, round(prompt_uppercase_count/prompt_length_raw, 4), 0) \
    | eval prompt_has_brackets=if(match(coalesce(input_text, ""), "[\[\]\{\}\<\>]"), 1, 0) \
    | eval prompt_has_delimiters=if(match(coalesce(input_text, ""), "(---|\*\*\*|###|```|\\[INST\\]|\\[/INST\\]|<<SYS>>|<</SYS>>|<\|im_start\|>|<\|im_end\|>)"), 1, 0) \
    | eval prompt_has_injection_markers=if(match(lower(coalesce(input_text, "")), "(ignore|disregard|forget|bypass|override).*(previous|prior|above|earlier|system|instruction|rule|prompt|safety|filter|guardrail)"), 1, 0) \
    | eval prompt_has_roleplay=if(match(lower(coalesce(input_text, "")), "(pretend|act as|imagine you are|you are now|from now on|new persona|new identity).*(no limits|unrestricted|unfiltered|without rules|anything)"), 1, 0) \
    | eval prompt_has_jailbreak_terms=if(match(lower(coalesce(input_text, "")), "(jailbreak|DAN|sudo mode|developer mode|god mode|admin mode|STAN|DUDE|AntiGPT|evil mode|uncensored|unaligned)"), 1, 0) \
    | eval prompt_has_encoding=if(match(coalesce(input_text, ""), "(\\\\x[0-9a-fA-F]{2}|%[0-9a-fA-F]{2}|&#\d+;|&#x[0-9a-fA-F]+;|base64|rot13|decode|encode|hex|ascii)"), 1, 0) \
    | eval prompt_has_repeated_chars=if(match(coalesce(input_text, ""), "(.)\\1{4,}"), 1, 0) \
    | eval prompt_pattern_score=(prompt_has_injection_markers*3 + prompt_has_jailbreak_terms*3 + prompt_has_roleplay*2 + prompt_has_encoding*2 + prompt_has_delimiters*1 + prompt_has_brackets*1 + prompt_has_repeated_chars*1) \
    | eval response_length_raw=len(coalesce(output_text, "")) \
    | eval response_special_char_count=len(replace(coalesce(output_text, ""), "[A-Za-z0-9\s]", "")) \
    | eval response_special_char_ratio=if(response_length_raw>0, round(response_special_char_count/response_length_raw, 4), 0) \
    | eval response_has_harmful_content=if(match(lower(coalesce(output_text, "")), "(how to make|instructions for|step by step).*(bomb|weapon|hack|exploit|attack|malware|virus|illegal|harmful)"), 1, 0) \
    | eval response_has_jailbreak_confirm=if(match(lower(coalesce(output_text, "")), "(i am now|i will now|entering|activated|enabled).*(DAN|jailbreak|unrestricted|unfiltered|bypass|developer mode)"), 1, 0) \
    | eval response_has_system_leak=if(match(lower(coalesce(output_text, "")), "(system prompt|my instructions|i was told|i am programmed|my purpose is|my rules are)"), 1, 0) \
    | eval response_pattern_score=(response_has_harmful_content*3 + response_has_jailbreak_confirm*3 + response_has_system_leak*2) \
    | eval input_text_clean=lower(coalesce(input_text, "")) \
    | eval input_text_clean=replace(input_text_clean, "[^a-z0-9\s]", " ") \
    | eval input_text_clean=replace(input_text_clean, "\s+", " ") \
    | eval input_text_clean=trim(input_text_clean) \
    | eval output_text_clean=lower(coalesce(output_text, "")) \
    | eval output_text_clean=replace(output_text_clean, "[^a-z0-9\s]", " ") \
    | eval output_text_clean=replace(output_text_clean, "\s+", " ") \
    | eval output_text_clean=trim(output_text_clean) \
    | eval has_valid_prompt=if(len(input_text_clean) > 20, 1, 0) \
    | eval has_valid_response=if(len(output_text_clean) > 50, 1, 0) \
    | where has_valid_prompt=1 OR has_valid_response=1
iseval = 0

# ============================================================================
# genai_tfidf_score_combined
# ============================================================================
# Applies trained TF-IDF anomaly models to score both prompts and responses
# Uses HYBRID DETECTION combining ML-based and rule-based pattern detection
# Requires models: tfidf_prompt_pca, prompt_anomaly_model, tfidf_response_pca, response_anomaly_model
#
# Usage:
#   index=gen_ai_cim | `genai_tfidf_preprocess_combined` | `genai_tfidf_score_combined`
# ============================================================================
[genai_tfidf_score_combined]
definition = \
    fit HashingVectorizer input_text_clean max_features=1000 ngram_range=1-2 stop_words=english reduce=false \
    | apply app:tfidf_prompt_pca \
    | apply app:prompt_anomaly_model \
    | eval prompt_isNormal = 'isNormal' \
    | eval "gen_ai.prompt.anomaly_score" = if(has_valid_prompt=1, prompt_isNormal, null()) \
    | eval prompt_ml_anomaly = if(has_valid_prompt=1 AND prompt_isNormal < `genai_tfidf_anomaly_threshold`, 1, 0) \
    | eval prompt_pattern_anomaly = if(has_valid_prompt=1 AND prompt_pattern_score >= `genai_tfidf_pattern_threshold`, 1, 0) \
    | eval "gen_ai.prompt.is_anomaly" = if(prompt_ml_anomaly=1 OR prompt_pattern_anomaly=1, "true", "false") \
    | eval "gen_ai.prompt.anomaly_source" = case( \
        prompt_ml_anomaly=1 AND prompt_pattern_anomaly=1, "ml_and_pattern", \
        prompt_ml_anomaly=1, "ml_only", \
        prompt_pattern_anomaly=1, "pattern_only", \
        1=1, "none" \
    ) \
    | fit HashingVectorizer output_text_clean max_features=1000 ngram_range=1-2 stop_words=english reduce=false \
    | apply app:tfidf_response_pca \
    | apply app:response_anomaly_model \
    | eval response_isNormal = 'isNormal' \
    | eval "gen_ai.response.anomaly_score" = if(has_valid_response=1, response_isNormal, null()) \
    | eval response_ml_anomaly = if(has_valid_response=1 AND response_isNormal < `genai_tfidf_anomaly_threshold`, 1, 0) \
    | eval response_pattern_anomaly = if(has_valid_response=1 AND response_pattern_score >= `genai_tfidf_pattern_threshold`, 1, 0) \
    | eval "gen_ai.response.is_anomaly" = if(response_ml_anomaly=1 OR response_pattern_anomaly=1, "true", "false") \
    | eval "gen_ai.response.anomaly_source" = case( \
        response_ml_anomaly=1 AND response_pattern_anomaly=1, "ml_and_pattern", \
        response_ml_anomaly=1, "ml_only", \
        response_pattern_anomaly=1, "pattern_only", \
        1=1, "none" \
    )
iseval = 0

# ============================================================================
# genai_tfidf_combined_risk
# ============================================================================
# Calculates combined anomaly risk level from prompt and response scores
#
# Usage:
#   ... | `genai_tfidf_score_prompt` | `genai_tfidf_score_response` | `genai_tfidf_combined_risk`
# ============================================================================
[genai_tfidf_combined_risk]
definition = \
    eval "gen_ai.tfidf.combined_anomaly" = case( \
        'gen_ai.prompt.is_anomaly'="true" AND 'gen_ai.response.is_anomaly'="true", "both", \
        'gen_ai.prompt.is_anomaly'="true", "prompt_only", \
        'gen_ai.response.is_anomaly'="true", "response_only", \
        1=1, "normal" \
    ) \
    | eval "gen_ai.tfidf.risk_level" = case( \
        'gen_ai.tfidf.combined_anomaly'="both", "HIGH", \
        'gen_ai.tfidf.combined_anomaly'="prompt_only", "MEDIUM", \
        'gen_ai.tfidf.combined_anomaly'="response_only", "LOW", \
        1=1, "NONE" \
    )
iseval = 0

# ============================================================================
# genai_tfidf_output_prompt
# ============================================================================
# Formats and outputs prompt anomaly scoring results as JSON for collection
# Creates _raw JSON object with all relevant fields for indexing
#
# Usage:
#   ... | `genai_tfidf_score_prompt` | `genai_tfidf_output_prompt`
# ============================================================================
[genai_tfidf_output_prompt]
definition = \
    eval _raw=json_object( \
        "timestamp", strftime(_time, "%Y-%m-%dT%H:%M:%S"), \
        "source", "tfidf_prompt_scoring", \
        "gen_ai.event.id", 'gen_ai.event.id', \
        "gen_ai.session.id", 'gen_ai.session.id', \
        "gen_ai.app.name", 'gen_ai.app.name', \
        "gen_ai.request.model", 'gen_ai.request.model', \
        "gen_ai.prompt.anomaly_score", 'gen_ai.prompt.anomaly_score', \
        "gen_ai.prompt.is_anomaly", 'gen_ai.prompt.is_anomaly', \
        "gen_ai.prompt.anomaly_source", 'gen_ai.prompt.anomaly_source', \
        "gen_ai.prompt.pattern_score", prompt_pattern_score, \
        "prompt_word_count", prompt_word_count, \
        "prompt_char_count", prompt_char_count, \
        "client.address", 'client.address', \
        "service.name", 'service.name', \
        "trace_id", 'trace_id' \
    ) \
    | collect index=gen_ai_log source="tfidf_prompt_scoring" sourcetype="gen_ai:tfidf:scoring"
iseval = 0

# ============================================================================
# genai_tfidf_output_response
# ============================================================================
# Formats and outputs response anomaly scoring results as JSON for collection
# Creates _raw JSON object with all relevant fields for indexing
#
# Usage:
#   ... | `genai_tfidf_score_response` | `genai_tfidf_output_response`
# ============================================================================
[genai_tfidf_output_response]
definition = \
    eval _raw=json_object( \
        "timestamp", strftime(_time, "%Y-%m-%dT%H:%M:%S"), \
        "source", "tfidf_response_scoring", \
        "gen_ai.event.id", 'gen_ai.event.id', \
        "gen_ai.session.id", 'gen_ai.session.id', \
        "gen_ai.app.name", 'gen_ai.app.name', \
        "gen_ai.request.model", 'gen_ai.request.model', \
        "gen_ai.response.anomaly_score", 'gen_ai.response.anomaly_score', \
        "gen_ai.response.is_anomaly", 'gen_ai.response.is_anomaly', \
        "gen_ai.response.anomaly_source", 'gen_ai.response.anomaly_source', \
        "gen_ai.response.pattern_score", response_pattern_score, \
        "response_word_count", response_word_count, \
        "response_char_count", response_char_count, \
        "client.address", 'client.address', \
        "service.name", 'service.name', \
        "trace_id", 'trace_id' \
    ) \
    | collect index=gen_ai_log source="tfidf_response_scoring" sourcetype="gen_ai:tfidf:scoring"
iseval = 0

# ============================================================================
# genai_tfidf_output_combined
# ============================================================================
# Formats and outputs combined anomaly scoring results as JSON for collection
# Includes both prompt and response scores plus combined risk level
#
# Usage:
#   ... | `genai_tfidf_combined_risk` | `genai_tfidf_output_combined`
# ============================================================================
[genai_tfidf_output_combined]
definition = \
    eval _raw=json_object( \
        "timestamp", strftime(_time, "%Y-%m-%dT%H:%M:%S"), \
        "source", "tfidf_combined_scoring", \
        "gen_ai.event.id", 'gen_ai.event.id', \
        "gen_ai.session.id", 'gen_ai.session.id', \
        "gen_ai.app.name", 'gen_ai.app.name', \
        "gen_ai.request.model", 'gen_ai.request.model', \
        "gen_ai.prompt.anomaly_score", 'gen_ai.prompt.anomaly_score', \
        "gen_ai.prompt.is_anomaly", 'gen_ai.prompt.is_anomaly', \
        "gen_ai.prompt.anomaly_source", 'gen_ai.prompt.anomaly_source', \
        "gen_ai.prompt.pattern_score", prompt_pattern_score, \
        "gen_ai.response.anomaly_score", 'gen_ai.response.anomaly_score', \
        "gen_ai.response.is_anomaly", 'gen_ai.response.is_anomaly', \
        "gen_ai.response.anomaly_source", 'gen_ai.response.anomaly_source', \
        "gen_ai.response.pattern_score", response_pattern_score, \
        "gen_ai.tfidf.combined_anomaly", 'gen_ai.tfidf.combined_anomaly', \
        "gen_ai.tfidf.risk_level", 'gen_ai.tfidf.risk_level', \
        "client.address", 'client.address', \
        "service.name", 'service.name', \
        "trace_id", 'trace_id' \
    ) \
    | collect index=gen_ai_log source="tfidf_combined_scoring" sourcetype="gen_ai:tfidf:scoring"
iseval = 0

# ============================================================================
# genai_tfidf_anomaly_stats(1)
# ============================================================================
# Aggregates TF-IDF anomaly statistics with time-based grouping
# Argument: time span (e.g., 1h, 1d, 1w)
#
# Usage:
#   index=gen_ai_cim gen_ai.tfidf.risk_level=* | `genai_tfidf_anomaly_stats(1h)`
# ============================================================================
[genai_tfidf_anomaly_stats(1)]
args = span
definition = \
    bucket _time span=$span$ \
    | stats count as total_events, \
            sum(eval(if('gen_ai.prompt.is_anomaly'="true", 1, 0))) as anomalous_prompts, \
            sum(eval(if('gen_ai.response.is_anomaly'="true", 1, 0))) as anomalous_responses, \
            sum(eval(if('gen_ai.tfidf.combined_anomaly'="both", 1, 0))) as high_risk_events, \
            avg('gen_ai.prompt.anomaly_score') as avg_prompt_score, \
            avg('gen_ai.response.anomaly_score') as avg_response_score, \
            dc(gen_ai.session.id) as unique_sessions, \
            dc(client.address) as unique_sources \
        by _time, gen_ai.deployment.id, gen_ai.app.name \
    | eval prompt_anomaly_rate = round((anomalous_prompts/total_events)*100, 2) \
    | eval response_anomaly_rate = round((anomalous_responses/total_events)*100, 2)
iseval = 0

# ============================================================================
# genai_tfidf_anomaly_by_model
# ============================================================================
# Aggregates TF-IDF anomalies by model
#
# Usage:
#   index=gen_ai_cim gen_ai.tfidf.risk_level=* | `genai_tfidf_anomaly_by_model`
# ============================================================================
[genai_tfidf_anomaly_by_model]
definition = \
    stats count as total_events, \
          sum(eval(if('gen_ai.prompt.is_anomaly'="true", 1, 0))) as anomalous_prompts, \
          sum(eval(if('gen_ai.response.is_anomaly'="true", 1, 0))) as anomalous_responses, \
          sum(eval(if('gen_ai.tfidf.combined_anomaly'="both", 1, 0))) as high_risk_events, \
          dc(gen_ai.session.id) as affected_sessions \
      by gen_ai.provider.name, gen_ai.request.model \
    | eval total_anomalies = anomalous_prompts + anomalous_responses \
    | eval anomaly_rate = round((total_anomalies/(total_events*2))*100, 2) \
    | sort - total_anomalies
iseval = 0

# ============================================================================
# genai_tfidf_anomaly_by_source
# ============================================================================
# Aggregates TF-IDF anomalies by client source address
#
# Usage:
#   index=gen_ai_cim gen_ai.tfidf.risk_level=* | `genai_tfidf_anomaly_by_source`
# ============================================================================
[genai_tfidf_anomaly_by_source]
definition = \
    stats count as total_events, \
          sum(eval(if('gen_ai.prompt.is_anomaly'="true", 1, 0))) as anomalous_prompts, \
          sum(eval(if('gen_ai.response.is_anomaly'="true", 1, 0))) as anomalous_responses, \
          sum(eval(if('gen_ai.tfidf.combined_anomaly'="both", 1, 0))) as high_risk_events, \
          values(gen_ai.tfidf.combined_anomaly) as anomaly_types, \
          values(gen_ai.app.name) as apps \
      by client.address \
    | where anomalous_prompts > 0 OR anomalous_responses > 0 \
    | eval total_anomalies = anomalous_prompts + anomalous_responses \
    | sort - total_anomalies
iseval = 0

###############################################################################
# PII DETECTION MACROS
###############################################################################

# ============================================================================
# genai_pii_extract_text
# ============================================================================
# Extracts and normalizes text from prompts and responses for PII analysis
# Handles multiple field formats from different providers
#
# Usage:
#   index=gen_ai_log | `genai_pii_extract_text`
# ============================================================================
[genai_pii_extract_text]
definition = \
    eval prompt_text='gen_ai.input.messages' \
    | eval response_text='gen_ai.output.messages' \
    | eval combined_text=prompt_text." ".response_text \
    | eval text_length=len(combined_text)
iseval = 0

# ============================================================================
# genai_pii_feature_engineering
# ============================================================================
# Comprehensive feature engineering for PII detection ML model
# Extracts pattern-based, statistical, and keyword features
#
# Usage:
#   index=gen_ai_log | `genai_pii_extract_text` | `genai_pii_feature_engineering`
# ============================================================================
[genai_pii_feature_engineering]
definition = \
    eval output_length=len(response_text) \
    | eval word_count=mvcount(split(response_text, " ")) \
    | rex field=response_text "(?<ssn_match>\d{3}-\d{2}-\d{4})" \
    | eval has_ssn=if(isnotnull(ssn_match), 1, 0) \
    | rex field=response_text "(?<email_match>[a-zA-Z0-9][a-zA-Z0-9._%+-]*@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})" \
    | eval has_email=if(isnotnull(email_match), 1, 0) \
    | rex field=response_text "(?<phone_match>(\(?\d{3}\)?[-.\s]?\d{3}[-.\s]?\d{4})|(\d{3}\.\d{3}\.\d{4}))" \
    | eval has_phone=if(isnotnull(phone_match), 1, 0) \
    | rex field=response_text "(?<dob_match>(?:date of birth|DOB|born):?\s*(?:\d{1,2}[/-]\d{1,2}[/-]\d{2,4}|(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+\d{1,2},?\s+\d{4}))" \
    | eval has_dob=if(isnotnull(dob_match), 1, 0) \
    | rex field=response_text "(?<address_match>\d+\s+[A-Za-z]+\s+(?:Street|St|Avenue|Ave|Road|Rd|Drive|Dr|Lane|Ln|Boulevard|Blvd|Way|Court|Ct|Place|Pl),?\s+[A-Z]?[a-z]+,?\s+[A-Z]{2}\s+\d{5})" \
    | eval has_address=if(isnotnull(address_match), 1, 0) \
    | rex field=response_text "(?<cc_match>\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4})" \
    | eval has_credit_card=if(isnotnull(cc_match), 1, 0) \
    | rex field=response_text "(?<name_match>(?:patient|for|Hi|Mr\.|Mrs\.|Ms\.|Dr\.)\s+([A-Z][a-z]+\s+[A-Z][a-z]+))" \
    | eval has_name=if(isnotnull(name_match), 1, 0) \
    | eval digit_count=len(replace(response_text, "[^\d]", "")) \
    | eval digit_ratio=if(output_length>0, round(digit_count/output_length, 4), 0) \
    | eval special_char_count=len(replace(response_text, "[A-Za-z0-9\s]", "")) \
    | eval special_char_ratio=if(output_length>0, round(special_char_count/output_length, 4), 0) \
    | eval uppercase_count=len(replace(response_text, "[^A-Z]", "")) \
    | eval uppercase_ratio=if(output_length>0, round(uppercase_count/output_length, 4), 0) \
    | fields - ssn_match, email_match, phone_match, dob_match, address_match, cc_match, name_match
iseval = 0

# ============================================================================
# genai_pii_apply_model
# ============================================================================
# Applies the trained PII detection model and generates risk scores
# Requires model: pii_detection_model
#
# Usage:
#   index=gen_ai_log | `genai_pii_extract_text` | `genai_pii_feature_engineering` | `genai_pii_apply_model`
# ============================================================================
[genai_pii_apply_model]
definition = \
    apply app:pii_detection_model \
    | eval "gen_ai.pii.risk_score" = round(coalesce('probability(pii_label=1)', 'predicted(pii_label)'), 4) \
    | eval "gen_ai.pii.ml_detected" = if('gen_ai.pii.risk_score' > 0.5, "true", "false") \
    | eval "gen_ai.pii.confidence" = case( \
        'gen_ai.pii.risk_score' > 0.9, "very_high", \
        'gen_ai.pii.risk_score' > 0.7, "high", \
        'gen_ai.pii.risk_score' > 0.5, "medium", \
        'gen_ai.pii.risk_score' > 0.3, "low", \
        1=1, "very_low" \
    )
iseval = 0

# ============================================================================
# genai_pii_classify_types
# ============================================================================
# Classifies detected PII into categories based on pattern matches
#
# Usage:
#   ... | `genai_pii_feature_engineering` | `genai_pii_classify_types`
# ============================================================================
[genai_pii_classify_types]
definition = \
    eval pii_types_detected = mvappend( \
        if(has_ssn=1, "SSN", null()), \
        if(has_email=1, "EMAIL", null()), \
        if(has_phone=1, "PHONE", null()), \
        if(has_dob=1, "DOB", null()), \
        if(has_address=1, "ADDRESS", null()), \
        if(has_credit_card=1, "CREDIT_CARD", null()), \
        if(has_name=1, "NAME", null()) \
    ) \
    | eval "gen_ai.pii.types" = mvjoin(pii_types_detected, ",") \
    | eval pii_type_count = mvcount(pii_types_detected) \
    | eval "gen_ai.pii.category" = case( \
        has_ssn=1 OR has_dob=1, "identity", \
        has_credit_card=1, "financial", \
        has_email=1 OR has_phone=1 OR has_address=1 OR has_name=1, "contact", \
        1=1, "none" \
    ) \
    | eval "gen_ai.pii.severity" = case( \
        has_ssn=1 OR has_credit_card=1, "critical", \
        has_dob=1, "high", \
        has_email=1 OR has_phone=1 OR has_address=1 OR has_name=1, "medium", \
        pii_type_count > 0, "low", \
        1=1, "none" \
    )
iseval = 0

# ============================================================================
# genai_pii_score_prompt
# ============================================================================
# Scores prompts (user inputs) for PII content
#
# Usage:
#   index=gen_ai_log | `genai_pii_score_prompt`
# ============================================================================
[genai_pii_score_prompt]
definition = \
    eval _pii_text='gen_ai.input.messages' \
    | eval _text_length=len(_pii_text) \
    | where isnotnull(_pii_text) AND _text_length > 5 \
    | rex field=_pii_text "(?<_ssn>\d{3}-\d{2}-\d{4})" \
    | rex field=_pii_text "(?<_email>[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})" \
    | rex field=_pii_text "(?<_phone>\(?\d{3}\)?[-.\s]?\d{3}[-.\s]?\d{4})" \
    | rex field=_pii_text "(?<_cc>\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4})" \
    | rex field=_pii_text "(?<_mrn>MRN\s+[A-Z0-9]{6,12})" \
    | rex field=_pii_text "(?<_member>MEM-[A-Z0-9-]{7,15})" \
    | eval "gen_ai.prompt.has_pii" = if(isnotnull(_ssn) OR isnotnull(_email) OR isnotnull(_phone) OR isnotnull(_cc) OR isnotnull(_mrn) OR isnotnull(_member), "true", "false") \
    | eval "gen_ai.prompt.pii_types" = mvjoin(mvappend( \
        if(isnotnull(_ssn), "SSN", null()), \
        if(isnotnull(_email), "EMAIL", null()), \
        if(isnotnull(_phone), "PHONE", null()), \
        if(isnotnull(_cc), "CREDIT_CARD", null()), \
        if(isnotnull(_mrn), "MRN", null()), \
        if(isnotnull(_member), "MEMBER_ID", null()) \
    ), ",") \
    | fields - _pii_text, _text_length, _ssn, _email, _phone, _cc, _mrn, _member
iseval = 0

# ============================================================================
# genai_pii_score_response
# ============================================================================
# Scores responses (AI outputs) for PII content
#
# Usage:
#   index=gen_ai_log | `genai_pii_score_response`
# ============================================================================
[genai_pii_score_response]
definition = \
    eval _pii_text='gen_ai.output.messages' \
    | eval _text_length=len(_pii_text) \
    | where isnotnull(_pii_text) AND _text_length > 5 \
    | rex field=_pii_text "(?<_ssn>\d{3}-\d{2}-\d{4})" \
    | rex field=_pii_text "(?<_email>[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})" \
    | rex field=_pii_text "(?<_phone>\(?\d{3}\)?[-.\s]?\d{3}[-.\s]?\d{4})" \
    | rex field=_pii_text "(?<_cc>\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4})" \
    | rex field=_pii_text "(?<_mrn>MRN\s+[A-Z0-9]{6,12})" \
    | rex field=_pii_text "(?<_member>MEM-[A-Z0-9-]{7,15})" \
    | rex field=_pii_text "(?<_name>(?:patient|for|Hi)\s+([A-Z][a-z]+\s+[A-Z][a-z]+))" \
    | rex field=_pii_text "(?<_medication>[A-Z][a-z]+(?:ine|ol|am|in|ate)\s+\d+\s*mg)" \
    | rex field=_pii_text "(?<_claim>CLM\d{8,12})" \
    | eval "gen_ai.response.has_pii" = if(isnotnull(_ssn) OR isnotnull(_email) OR isnotnull(_phone) OR isnotnull(_cc) OR isnotnull(_mrn) OR isnotnull(_member) OR isnotnull(_name) OR isnotnull(_medication) OR isnotnull(_claim), "true", "false") \
    | eval "gen_ai.response.pii_types" = mvjoin(mvappend( \
        if(isnotnull(_ssn), "SSN", null()), \
        if(isnotnull(_email), "EMAIL", null()), \
        if(isnotnull(_phone), "PHONE", null()), \
        if(isnotnull(_cc), "CREDIT_CARD", null()), \
        if(isnotnull(_mrn), "MRN", null()), \
        if(isnotnull(_member), "MEMBER_ID", null()), \
        if(isnotnull(_name), "NAME", null()), \
        if(isnotnull(_medication), "MEDICATION", null()), \
        if(isnotnull(_claim), "CLAIM_NUMBER", null()) \
    ), ",") \
    | fields - _pii_text, _text_length, _ssn, _email, _phone, _cc, _mrn, _member, _name, _medication, _claim
iseval = 0

# ============================================================================
# genai_pii_combined_score
# ============================================================================
# Combined PII scoring for both prompts and responses
#
# Usage:
#   index=gen_ai_log | `genai_pii_combined_score`
# ============================================================================
[genai_pii_combined_score]
definition = \
    `genai_pii_score_prompt` \
    | `genai_pii_score_response` \
    | eval "gen_ai.pii.detected" = if('gen_ai.prompt.has_pii'="true" OR 'gen_ai.response.has_pii'="true", "true", "false") \
    | eval "gen_ai.pii.location" = case( \
        'gen_ai.prompt.has_pii'="true" AND 'gen_ai.response.has_pii'="true", "both", \
        'gen_ai.prompt.has_pii'="true", "prompt", \
        'gen_ai.response.has_pii'="true", "response", \
        1=1, "none" \
    ) \
    | eval "gen_ai.pii.types" = mvjoin(mvdedup(mvappend(split('gen_ai.prompt.pii_types', ","), split('gen_ai.response.pii_types', ","))), ",")
iseval = 0

# ============================================================================
# genai_pii_stats_by_model(1)
# ============================================================================
# Aggregates PII detection statistics by model with time span
# Argument: time span (e.g., 1h, 1d)
#
# Usage:
#   index=gen_ai_log | `genai_pii_combined_score` | `genai_pii_stats_by_model(1h)`
# ============================================================================
[genai_pii_stats_by_model(1)]
args = span
definition = \
    bucket _time span=$span$ \
    | stats count as total_events, \
            sum(eval(if('gen_ai.pii.detected'="true", 1, 0))) as pii_events, \
            sum(eval(if('gen_ai.prompt.has_pii'="true", 1, 0))) as pii_in_prompts, \
            sum(eval(if('gen_ai.response.has_pii'="true", 1, 0))) as pii_in_responses, \
            dc(gen_ai.session.id) as unique_sessions \
        by _time, gen_ai.provider.name, gen_ai.request.model \
    | eval pii_rate = round((pii_events/total_events)*100, 2) \
    | eval prompt_pii_rate = round((pii_in_prompts/total_events)*100, 2) \
    | eval response_pii_rate = round((pii_in_responses/total_events)*100, 2)
iseval = 0

# ============================================================================
# genai_pii_stats_by_app
# ============================================================================
# Aggregates PII detection statistics by application
#
# Usage:
#   index=gen_ai_log | `genai_pii_combined_score` | `genai_pii_stats_by_app`
# ============================================================================
[genai_pii_stats_by_app]
definition = \
    stats count as total_events, \
          sum(eval(if('gen_ai.pii.detected'="true", 1, 0))) as pii_events, \
          sum(eval(if('gen_ai.pii.location'="both", 1, 0))) as pii_both_locations, \
          dc(gen_ai.session.id) as affected_sessions, \
          values(gen_ai.pii.types) as pii_types_seen \
      by gen_ai.app.name \
    | eval pii_rate = round((pii_events/total_events)*100, 2) \
    | sort - pii_events
iseval = 0

# ============================================================================
# genai_pii_high_risk_threshold(1)
# ============================================================================
# Filters events to those above a specified PII risk threshold
# Argument: threshold value (e.g., 0.7)
#
# Usage:
#   index=gen_ai_log | `genai_pii_extract_text` | `genai_pii_feature_engineering` | `genai_pii_apply_model` | `genai_pii_high_risk_threshold(0.7)`
# ============================================================================
[genai_pii_high_risk_threshold(1)]
args = threshold
definition = \
    where 'gen_ai.pii.risk_score' > $threshold$ \
    | eval pii_alert_level = case( \
        'gen_ai.pii.risk_score' > 0.9, "CRITICAL", \
        'gen_ai.pii.risk_score' > 0.7, "HIGH", \
        'gen_ai.pii.risk_score' > 0.5, "MEDIUM", \
        1=1, "LOW" \
    )
iseval = 0

###############################################################################
# PROMPT INJECTION DETECTION MACROS
###############################################################################

# ============================================================================
# genai_prompt_injection_extract_text
# ============================================================================
# Extracts and normalizes text from prompts for injection analysis
# Handles multiple field formats from different providers
#
# Usage:
#   index=gen_ai_log | `genai_prompt_injection_extract_text`
# ============================================================================
[genai_prompt_injection_extract_text]
definition = \
    eval input_text=coalesce('gen_ai.input.messages', 'event.input', input) \
    | where isnotnull(input_text) AND len(input_text) > 0
iseval = 0

# ============================================================================
# genai_prompt_injection_feature_engineering
# ============================================================================
# Comprehensive feature engineering for prompt injection detection ML model
# Extracts adversarial keyword, statistical, and structural features
#
# Usage:
#   index=gen_ai_log | `genai_prompt_injection_extract_text` | `genai_prompt_injection_feature_engineering`
# ============================================================================
[genai_prompt_injection_feature_engineering]
definition = \
    eval prompt_length=len(input_text) \
    | eval word_count=mvcount(split(input_text, " ")) \
    | eval has_ignore_instruction=if(match(input_text, "(?i)(ignore|disregard|forget).*(previous|prior|above|earlier).*(instruction|prompt|rule|guideline)"), 1, 0) \
    | eval has_reveal_request=if(match(input_text, "(?i)(reveal|show|display|tell me|what is).*(system|original|hidden).*(prompt|instruction|rule)"), 1, 0) \
    | eval has_bypass_request=if(match(input_text, "(?i)(bypass|override|disable|turn off).*(safety|filter|guardrail|restriction|limit)"), 1, 0) \
    | eval has_roleplay_injection=if(match(input_text, "(?i)(pretend|act as|imagine you are|you are now|from now on).*(unrestricted|unfiltered|without limits|no rules)"), 1, 0) \
    | eval has_jailbreak_terms=if(match(input_text, "(?i)(jailbreak|DAN mode|sudo mode|developer mode|god mode|admin mode|STAN|DUDE|AntiGPT)"), 1, 0) \
    | eval has_encoding=if(match(input_text, "(\\\\x[0-9a-fA-F]{2}|%[0-9a-fA-F]{2}|&#\d+;|&#x[0-9a-fA-F]+;|base64|rot13|decode)"), 1, 0) \
    | eval special_char_count=len(replace(input_text, "[A-Za-z0-9\s]", "")) \
    | eval special_char_ratio=if(prompt_length>0, round(special_char_count/prompt_length, 4), 0) \
    | rex field=input_text max_match=100 "(?i)(?<negation_match>don't|do not|never|not|no|none)" \
    | eval negation_count=if(isnull(negation_match), 0, mvcount(negation_match)) \
    | eval negation_density=if(word_count>0, round(negation_count/word_count, 4), 0) \
    | eval starts_with_command=if(match(input_text, "(?i)^(ignore|disregard|forget|reveal|show|tell|bypass|override|enable|activate|switch|enter|turn)"), 1, 0)
iseval = 0

# ============================================================================
# genai_prompt_injection_apply_model
# ============================================================================
# Applies the trained prompt injection detection model and generates risk scores
# Requires model: prompt_injection_model
#
# Usage:
#   index=gen_ai_log | `genai_prompt_injection_extract_text` | `genai_prompt_injection_feature_engineering` | `genai_prompt_injection_apply_model`
# ============================================================================
[genai_prompt_injection_apply_model]
definition = \
    apply app:prompt_injection_model \
    | eval "gen_ai.prompt_injection.risk_score" = round('predicted(injection_label)', 4) \
    | eval "gen_ai.prompt_injection.ml_detected" = if('gen_ai.prompt_injection.risk_score' > 0.6, "true", "false") \
    | eval "gen_ai.prompt_injection.confidence" = case( \
        'gen_ai.prompt_injection.risk_score' > 0.9, "very_high", \
        'gen_ai.prompt_injection.risk_score' > 0.8, "high", \
        'gen_ai.prompt_injection.risk_score' > 0.6, "medium", \
        'gen_ai.prompt_injection.risk_score' > 0.4, "low", \
        1=1, "very_low" \
    ) \
    | eval "gen_ai.prompt_injection.severity" = case( \
        'gen_ai.prompt_injection.risk_score' > 0.9, "critical", \
        'gen_ai.prompt_injection.risk_score' > 0.7, "high", \
        'gen_ai.prompt_injection.risk_score' > 0.5, "medium", \
        'gen_ai.prompt_injection.risk_score' > 0.3, "low", \
        1=1, "none" \
    )
iseval = 0

# ============================================================================
# genai_prompt_injection_classify_techniques
# ============================================================================
# Classifies detected prompt injections by attack technique type
#
# Usage:
#   ... | `genai_prompt_injection_feature_engineering` | `genai_prompt_injection_classify_techniques`
# ============================================================================
[genai_prompt_injection_classify_techniques]
definition = \
    eval injection_techniques_detected = mvappend( \
        if(has_ignore_instruction=1, "ignore_instructions", null()), \
        if(has_reveal_request=1, "reveal_system", null()), \
        if(has_bypass_request=1, "bypass_safety", null()), \
        if(has_roleplay_injection=1, "roleplay_injection", null()), \
        if(has_jailbreak_terms=1, "jailbreak", null()), \
        if(has_encoding=1, "encoding_obfuscation", null()) \
    ) \
    | eval "gen_ai.prompt_injection.technique" = case( \
        has_jailbreak_terms=1, "jailbreak", \
        has_ignore_instruction=1, "ignore_instructions", \
        has_reveal_request=1, "reveal_system", \
        has_bypass_request=1, "bypass_safety", \
        has_roleplay_injection=1, "roleplay_injection", \
        has_encoding=1, "encoding_obfuscation", \
        1=1, "unknown" \
    ) \
    | eval "gen_ai.prompt_injection.techniques" = mvjoin(injection_techniques_detected, ",") \
    | eval "gen_ai.prompt_injection.category" = case( \
        has_jailbreak_terms=1 OR has_bypass_request=1, "security_bypass", \
        has_reveal_request=1, "data_exfiltration", \
        has_ignore_instruction=1, "instruction_manipulation", \
        has_roleplay_injection=1, "social_engineering", \
        has_encoding=1, "obfuscation", \
        1=1, "unknown" \
    )
iseval = 0

# ============================================================================
# genai_prompt_injection_score
# ============================================================================
# Complete scoring pipeline for prompt injection detection
# Combines extraction, feature engineering, model application, and classification
#
# Usage:
#   index=gen_ai_log | `genai_prompt_injection_score`
# ============================================================================
[genai_prompt_injection_score]
definition = \
    `genai_prompt_injection_extract_text` \
    | `genai_prompt_injection_feature_engineering` \
    | `genai_prompt_injection_apply_model` \
    | `genai_prompt_injection_classify_techniques`
iseval = 0

# ============================================================================
# genai_prompt_injection_high_risk_threshold(1)
# ============================================================================
# Filters events to those above a specified prompt injection risk threshold
# Argument: threshold value (e.g., 0.7)
#
# Usage:
#   index=gen_ai_log | `genai_prompt_injection_score` | `genai_prompt_injection_high_risk_threshold(0.7)`
# ============================================================================
[genai_prompt_injection_high_risk_threshold(1)]
args = threshold
definition = \
    where 'gen_ai.prompt_injection.risk_score' > $threshold$ \
    | eval injection_alert_level = case( \
        'gen_ai.prompt_injection.risk_score' > 0.9, "CRITICAL", \
        'gen_ai.prompt_injection.risk_score' > 0.7, "HIGH", \
        'gen_ai.prompt_injection.risk_score' > 0.5, "MEDIUM", \
        1=1, "LOW" \
    )
iseval = 0

# ============================================================================
# genai_prompt_injection_stats_by_technique
# ============================================================================
# Aggregates prompt injection detection statistics by technique type
#
# Usage:
#   index=gen_ai_log | `genai_prompt_injection_score` | `genai_prompt_injection_stats_by_technique`
# ============================================================================
[genai_prompt_injection_stats_by_technique]
definition = \
    stats count as total_detections, \
          avg('gen_ai.prompt_injection.risk_score') as avg_risk, \
          max('gen_ai.prompt_injection.risk_score') as max_risk, \
          dc(client.address) as unique_sources, \
          dc('gen_ai.session.id') as unique_sessions \
          by 'gen_ai.prompt_injection.technique' \
    | sort -total_detections
iseval = 0

# ============================================================================
# genai_prompt_injection_stats_by_app
# ============================================================================
# Aggregates prompt injection detection statistics by application
#
# Usage:
#   index=gen_ai_log | `genai_prompt_injection_score` | `genai_prompt_injection_stats_by_app`
# ============================================================================
[genai_prompt_injection_stats_by_app]
definition = \
    stats count as total_events, \
          sum(eval(if('gen_ai.prompt_injection.ml_detected'="true", 1, 0))) as injection_events, \
          avg('gen_ai.prompt_injection.risk_score') as avg_risk_score, \
          dc('gen_ai.session.id') as unique_sessions \
          by 'gen_ai.app.name' \
    | eval injection_rate = round((injection_events/total_events)*100, 2) \
    | sort -injection_events
iseval = 0

###############################################################################
# REVIEW WORKFLOW MACROS
###############################################################################

# ============================================================================
# gen_ai_event_id
# ============================================================================
# Generate a unique event ID for events missing gen_ai.event.id
#
# Usage:
#   index=gen_ai_log | `gen_ai_event_id`
# ============================================================================
[gen_ai_event_id]
definition = eval event_id=coalesce('gen_ai.event.id', 'gen_ai.response.id', md5(_time.trace_id._raw))
iseval = 0

# Generate event ID with custom fallback fields
[gen_ai_event_id(2)]
args = fallback1, fallback2
definition = eval event_id=coalesce('gen_ai.event.id', 'gen_ai.response.id', $fallback1$, $fallback2$, md5(_time.trace_id._raw))
iseval = 0

# ============================================================================
# gen_ai_high_risk_filter
# ============================================================================
# Filter for high-risk events (automated flags triggered)
#
# Usage:
#   index=gen_ai_log | search `gen_ai_high_risk_filter`
# ============================================================================
[gen_ai_high_risk_filter]
definition = ('gen_ai.pii.detected'="true" OR 'gen_ai.safety.violated'="true" OR 'gen_ai.guardrail.triggered'="true" OR 'gen_ai.policy.blocked'="true")
iseval = 0

# Filter for any flagged event
[gen_ai_any_flag_filter]
definition = ('gen_ai.pii.detected'="true" OR 'gen_ai.safety.violated'="true" OR 'gen_ai.guardrail.triggered'="true" OR 'gen_ai.policy.blocked'="true" OR 'gen_ai.prompt.anomaly_score'>0.7 OR 'gen_ai.response.anomaly_score'>0.7)
iseval = 0

# ============================================================================
# gen_ai_add_review_status
# ============================================================================
# Add review status via lookup (uses underscore field names in KV store)
#
# Usage:
#   index=gen_ai_log | `gen_ai_event_id` | `gen_ai_add_review_status`
# ============================================================================
[gen_ai_add_review_status]
definition = eval gen_ai_event_id='gen_ai.event.id' | lookup gen_ai_review_findings_lookup gen_ai_event_id OUTPUT gen_ai_review_status AS review_status, gen_ai_review_assignee AS assignee, gen_ai_review_reviewer AS reviewer, gen_ai_review_priority AS priority, gen_ai_review_pii_confirmed AS pii_confirmed, gen_ai_review_phi_confirmed AS phi_confirmed, gen_ai_review_prompt_injection_confirmed AS prompt_injection_confirmed, gen_ai_review_anomaly_prompt_detected AS anomaly_prompt_detected, gen_ai_review_anomaly_prompt_reviewed AS anomaly_prompt_reviewed, gen_ai_review_anomaly_response_detected AS anomaly_response_detected, gen_ai_review_anomaly_response_reviewed AS anomaly_response_reviewed, gen_ai_review_updated_at AS review_updated | eval review_status=coalesce(review_status, "unreviewed")
iseval = 0

# Calculate risk score based on automated flags
[gen_ai_calc_risk_score]
definition = eval risk_score=(if('gen_ai.pii.detected'="true", 30, 0) + if('gen_ai.safety.violated'="true", 40, 0) + if('gen_ai.guardrail.triggered'="true", 20, 0) + if('gen_ai.policy.blocked'="true", 10, 0))
iseval = 0

# ============================================================================
# gen_ai_any_issue_confirmed
# ============================================================================
# Check if any issue was confirmed in a review
#
# Usage:
#   | inputlookup gen_ai_review_findings_lookup | where `gen_ai_any_issue_confirmed`
# ============================================================================
[gen_ai_any_issue_confirmed]
definition = (('gen_ai.review.pii_confirmed'="true" OR 'gen_ai.review.pii_confirmed'=1) OR ('gen_ai.review.phi_confirmed'="true" OR 'gen_ai.review.phi_confirmed'=1) OR ('gen_ai.review.prompt_injection_confirmed'="true" OR 'gen_ai.review.prompt_injection_confirmed'=1) OR 'gen_ai.review.anomaly_prompt_reviewed'="TRUE" OR 'gen_ai.review.anomaly_response_reviewed'="TRUE")
iseval = 0

# Count confirmed issue types
[gen_ai_count_issue_types]
definition = eval issue_count=(if('gen_ai.review.pii_confirmed'="true" OR 'gen_ai.review.pii_confirmed'=1, 1, 0) + if('gen_ai.review.phi_confirmed'="true" OR 'gen_ai.review.phi_confirmed'=1, 1, 0) + if('gen_ai.review.prompt_injection_confirmed'="true" OR 'gen_ai.review.prompt_injection_confirmed'=1, 1, 0) + if('gen_ai.review.anomaly_prompt_reviewed'="TRUE" OR 'gen_ai.review.anomaly_response_reviewed'="TRUE", 1, 0))
iseval = 0

# ============================================================================
# Time-based filtering macros
# ============================================================================
# Filter for records updated within timeframe (in seconds)
[gen_ai_updated_within(1)]
args = seconds
definition = where 'gen_ai.review.updated_at' > (now() - $seconds$)
iseval = 0

# Filter for records created within timeframe (in seconds)
[gen_ai_created_within(1)]
args = seconds
definition = where 'gen_ai.review.created_at' > (now() - $seconds$)
iseval = 0
